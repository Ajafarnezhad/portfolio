{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persian Sentiment Analysis and Visualization\n",
    "\n",
    "\n",
    "# Importing essential libraries for text processing, sentiment analysis, and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud_fa import WordCloudFa\n",
    "from hazm import Normalizer, WordTokenizer, stopwords_list\n",
    "from textblob import TextBlob  # For rule-based sentiment analysis\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setting up a professional visualization theme\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# --- 1. Data Loading and Initial Inspection ---\n",
    "# Load the comments dataset\n",
    "df = pd.read_csv('nazar.csv')\n",
    "\n",
    "# Display dataset overview\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 Comments:\")\n",
    "print(df['nazaar'].head())\n",
    "\n",
    "# --- 2. Text Preprocessing ---\n",
    "# Initialize Hazm tools for Persian text processing\n",
    "normalizer = Normalizer()\n",
    "tokenizer = WordTokenizer()\n",
    "stopwords = set(stopwords_list())  # Load default Hazm stopwords\n",
    "\n",
    "# Load custom stopwords from file\n",
    "with open('stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    custom_stopwords = set(f.read().splitlines())\n",
    "stopwords.update(custom_stopwords)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess Persian text: normalize, tokenize, and remove stopwords.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    # Normalize text (e.g., unify characters, remove diacritics)\n",
    "    text = normalizer.normalize(text)\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to comments\n",
    "df['cleaned_text'] = df['nazaar'].apply(preprocess_text)\n",
    "\n",
    "# --- 3. Sentiment Analysis ---\n",
    "def get_sentiment(text):\n",
    "    \"\"\"Perform rule-based sentiment analysis using TextBlob polarity.\"\"\"\n",
    "    # Translate Persian text to English for TextBlob (as a simple workaround)\n",
    "    # Note: For production, use a Persian-specific sentiment model like ParsBERT\n",
    "    # Here, we use a rule-based approach for simplicity\n",
    "    if not text:\n",
    "        return 'Neutral'\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        return 'Positive'\n",
    "    elif polarity < -0.1:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['sentiment'] = df['cleaned_text'].apply(get_sentiment)\n",
    "\n",
    "# Display sentiment distribution\n",
    "print(\"\\nSentiment Distribution:\")\n",
    "print(df['sentiment'].value_counts())\n",
    "\n",
    "# --- 4. Exploratory Data Analysis (EDA) ---\n",
    "# Visualize sentiment distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='sentiment', data=df, palette='coolwarm', order=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title('Sentiment Distribution of Mentorship Comments', pad=20)\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.show()\n",
    "\n",
    "# Combine all cleaned text for word cloud\n",
    "all_text = ' '.join(df['cleaned_text'])\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloudFa(\n",
    "    persian_normalize=True,\n",
    "    include_numbers=False,\n",
    "    background_color='white',\n",
    "    width=1400,\n",
    "    height=800,\n",
    "    stopwords=stopwords,\n",
    "    font_path='path/to/persian_font.ttf'  # Replace with a valid Persian font path, e.g., 'B Nazanin'\n",
    ")\n",
    "wc = wordcloud.generate(all_text)\n",
    "\n",
    "# Visualize word cloud\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Mentorship Comments', pad=20)\n",
    "plt.show()\n",
    "\n",
    "# Save word cloud\n",
    "wc.to_file('wordcloud.png')\n",
    "\n",
    "# Word frequency analysis\n",
    "word_freq = pd.Series(' '.join(df['cleaned_text']).split()).value_counts().head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=word_freq.values, y=word_freq.index, palette='viridis')\n",
    "plt.title('Top 10 Most Frequent Words in Comments', pad=20)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Word')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ---  Save Results ---\n",
    "# Save processed dataset with sentiments\n",
    "df.to_csv('processed_nazar.csv', index=False, encoding='utf-8')\n",
    "print(\"\\nProcessed dataset saved as 'processed_nazar.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
